{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fedbf825",
   "metadata": {},
   "source": [
    "# Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1a7370d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7299e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/sonar.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2b4e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 60)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1].to_numpy()\n",
    "Y = df.iloc[:,-1].to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf63460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeebc697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = LabelEncoder()\n",
    "Y = e.fit_transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "507ae1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 24)                1464      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,489\n",
      "Trainable params: 1,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "612841cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff83ee89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5385\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.5769\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.5865\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6010\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6424 - accuracy: 0.6154\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.6538\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6250 - accuracy: 0.6971\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.6683\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.7019\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5968 - accuracy: 0.7260\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 0.7260\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7452\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.7500\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5606 - accuracy: 0.7500\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7548\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5449 - accuracy: 0.7692\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5354 - accuracy: 0.7933\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.7596\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7788\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.7885\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.8125\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7885\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.8029\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.7981\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7981\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7933\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7885\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.8077\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.8221\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.8173\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8221\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.8029\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.8125\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8221\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 997us/step - loss: 0.4360 - accuracy: 0.8269\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8221\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4263 - accuracy: 0.8269\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8173\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8269\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8221\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.8413\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4075 - accuracy: 0.8365\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4056 - accuracy: 0.8317\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4013 - accuracy: 0.8221\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8317\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3964 - accuracy: 0.8365\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8221\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8413\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3894 - accuracy: 0.8462\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2156d4ade80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04032cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_review_model.h5')\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f8ca06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 24)                1464      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,489\n",
      "Trainable params: 1,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('my_review_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a22d17de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4     5     6       7     8     9    10  11  12\n",
       "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
       "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
       "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1\n",
       "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8   6   1\n",
       "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/wine.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f26ba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,:-1].to_numpy()\n",
    "Y=df.iloc[:,-1].to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed761dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 30)                390       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 12)                372       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(30, activation='relu', input_dim=12))\n",
    "model.add(keras.layers.Dense(12, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "213ffe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d37d004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./model/'):\n",
    "    os.mkdir('./model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8be35cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = './model/{epoch:03d}-{val_loss:0.4f}.hdf5'\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath = modelpath,\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 1,\n",
    "    save_best_only = True\n",
    ")\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    patience = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6286168",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 1/10 [==>...........................] - ETA: 4s - loss: 1.8284 - accuracy: 0.3520\n",
      "Epoch 1: val_loss improved from inf to 0.54463, saving model to ./model\\001-0.5446.hdf5\n",
      "10/10 [==============================] - 1s 27ms/step - loss: 1.0106 - accuracy: 0.4418 - val_loss: 0.5446 - val_accuracy: 0.9672\n",
      "Epoch 2/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.4827 - accuracy: 0.8520\n",
      "Epoch 2: val_loss improved from 0.54463 to 0.22752, saving model to ./model\\002-0.2275.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8568 - val_loss: 0.2275 - val_accuracy: 0.9738\n",
      "Epoch 3/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.3057 - accuracy: 0.8700\n",
      "Epoch 3: val_loss improved from 0.22752 to 0.21399, saving model to ./model\\003-0.2140.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3117 - accuracy: 0.8669 - val_loss: 0.2140 - val_accuracy: 0.9631\n",
      "Epoch 4/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2780 - accuracy: 0.9020\n",
      "Epoch 4: val_loss did not improve from 0.21399\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.8940 - val_loss: 0.2659 - val_accuracy: 0.9390\n",
      "Epoch 5/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2921 - accuracy: 0.8860\n",
      "Epoch 5: val_loss did not improve from 0.21399\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2665 - accuracy: 0.9017 - val_loss: 0.2158 - val_accuracy: 0.9533\n",
      "Epoch 6/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2329 - accuracy: 0.9160\n",
      "Epoch 6: val_loss did not improve from 0.21399\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2549 - accuracy: 0.9050 - val_loss: 0.2278 - val_accuracy: 0.9477\n",
      "Epoch 7/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2744 - accuracy: 0.8940\n",
      "Epoch 7: val_loss did not improve from 0.21399\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2480 - accuracy: 0.9072 - val_loss: 0.2312 - val_accuracy: 0.9462\n",
      "Epoch 8/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2024 - accuracy: 0.9280\n",
      "Epoch 8: val_loss improved from 0.21399 to 0.20540, saving model to ./model\\008-0.2054.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2428 - accuracy: 0.9092 - val_loss: 0.2054 - val_accuracy: 0.9574\n",
      "Epoch 9/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1884 - accuracy: 0.9320\n",
      "Epoch 9: val_loss did not improve from 0.20540\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2386 - accuracy: 0.9112 - val_loss: 0.2294 - val_accuracy: 0.9446\n",
      "Epoch 10/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2271 - accuracy: 0.9160\n",
      "Epoch 10: val_loss did not improve from 0.20540\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2373 - accuracy: 0.9122 - val_loss: 0.2198 - val_accuracy: 0.9477\n",
      "Epoch 11/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2188 - accuracy: 0.9200\n",
      "Epoch 11: val_loss improved from 0.20540 to 0.19961, saving model to ./model\\011-0.1996.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2344 - accuracy: 0.9136 - val_loss: 0.1996 - val_accuracy: 0.9569\n",
      "Epoch 12/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1958 - accuracy: 0.9320\n",
      "Epoch 12: val_loss did not improve from 0.19961\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2328 - accuracy: 0.9147 - val_loss: 0.2216 - val_accuracy: 0.9441\n",
      "Epoch 13/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2137 - accuracy: 0.9280\n",
      "Epoch 13: val_loss did not improve from 0.19961\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2316 - accuracy: 0.9144 - val_loss: 0.2046 - val_accuracy: 0.9513\n",
      "Epoch 14/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2631 - accuracy: 0.8960\n",
      "Epoch 14: val_loss did not improve from 0.19961\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2301 - accuracy: 0.9144 - val_loss: 0.2085 - val_accuracy: 0.9503\n",
      "Epoch 15/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1830 - accuracy: 0.9360\n",
      "Epoch 15: val_loss did not improve from 0.19961\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2295 - accuracy: 0.9149 - val_loss: 0.2146 - val_accuracy: 0.9497\n",
      "Epoch 16/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2224 - accuracy: 0.9180\n",
      "Epoch 16: val_loss improved from 0.19961 to 0.18541, saving model to ./model\\016-0.1854.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2284 - accuracy: 0.9142 - val_loss: 0.1854 - val_accuracy: 0.9605\n",
      "Epoch 17/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2168 - accuracy: 0.9260\n",
      "Epoch 17: val_loss did not improve from 0.18541\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2262 - accuracy: 0.9153 - val_loss: 0.2322 - val_accuracy: 0.9431\n",
      "Epoch 18/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1819 - accuracy: 0.9380\n",
      "Epoch 18: val_loss did not improve from 0.18541\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2266 - accuracy: 0.9164 - val_loss: 0.2003 - val_accuracy: 0.9569\n",
      "Epoch 19/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1905 - accuracy: 0.9260\n",
      "Epoch 19: val_loss did not improve from 0.18541\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2245 - accuracy: 0.9169 - val_loss: 0.2045 - val_accuracy: 0.9492\n",
      "Epoch 20/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2336 - accuracy: 0.9160\n",
      "Epoch 20: val_loss did not improve from 0.18541\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2238 - accuracy: 0.9175 - val_loss: 0.2008 - val_accuracy: 0.9544\n",
      "Epoch 21/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2302 - accuracy: 0.9060\n",
      "Epoch 21: val_loss improved from 0.18541 to 0.18429, saving model to ./model\\021-0.1843.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2219 - accuracy: 0.9180 - val_loss: 0.1843 - val_accuracy: 0.9585\n",
      "Epoch 22/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2337 - accuracy: 0.9020\n",
      "Epoch 22: val_loss did not improve from 0.18429\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2213 - accuracy: 0.9177 - val_loss: 0.1991 - val_accuracy: 0.9559\n",
      "Epoch 23/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2187 - accuracy: 0.9220\n",
      "Epoch 23: val_loss did not improve from 0.18429\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2204 - accuracy: 0.9193 - val_loss: 0.1951 - val_accuracy: 0.9579\n",
      "Epoch 24/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1921 - accuracy: 0.9320\n",
      "Epoch 24: val_loss did not improve from 0.18429\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2189 - accuracy: 0.9188 - val_loss: 0.1950 - val_accuracy: 0.9554\n",
      "Epoch 25/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2393 - accuracy: 0.9120\n",
      "Epoch 25: val_loss did not improve from 0.18429\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2184 - accuracy: 0.9193 - val_loss: 0.2011 - val_accuracy: 0.9528\n",
      "Epoch 26/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2546 - accuracy: 0.9100\n",
      "Epoch 26: val_loss did not improve from 0.18429\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2169 - accuracy: 0.9186 - val_loss: 0.1965 - val_accuracy: 0.9549\n",
      "Epoch 27/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2014 - accuracy: 0.9160\n",
      "Epoch 27: val_loss did not improve from 0.18429\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2150 - accuracy: 0.9202 - val_loss: 0.1852 - val_accuracy: 0.9569\n",
      "Epoch 28/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1944 - accuracy: 0.9260\n",
      "Epoch 28: val_loss did not improve from 0.18429\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2135 - accuracy: 0.9206 - val_loss: 0.1981 - val_accuracy: 0.9518\n",
      "Epoch 29/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2326 - accuracy: 0.9100\n",
      "Epoch 29: val_loss did not improve from 0.18429\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2122 - accuracy: 0.9219 - val_loss: 0.1927 - val_accuracy: 0.9533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2384 - accuracy: 0.9100\n",
      "Epoch 30: val_loss improved from 0.18429 to 0.17496, saving model to ./model\\030-0.1750.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2104 - accuracy: 0.9215 - val_loss: 0.1750 - val_accuracy: 0.9585\n",
      "Epoch 31/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2092 - accuracy: 0.9260\n",
      "Epoch 31: val_loss did not improve from 0.17496\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2086 - accuracy: 0.9226 - val_loss: 0.2052 - val_accuracy: 0.9487\n",
      "Epoch 32/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1967 - accuracy: 0.9300\n",
      "Epoch 32: val_loss did not improve from 0.17496\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2063 - accuracy: 0.9239 - val_loss: 0.1964 - val_accuracy: 0.9518\n",
      "Epoch 33/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2297 - accuracy: 0.9100\n",
      "Epoch 33: val_loss did not improve from 0.17496\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2040 - accuracy: 0.9257 - val_loss: 0.1769 - val_accuracy: 0.9605\n",
      "Epoch 34/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2082 - accuracy: 0.9240\n",
      "Epoch 34: val_loss improved from 0.17496 to 0.16414, saving model to ./model\\034-0.1641.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2001 - accuracy: 0.9252 - val_loss: 0.1641 - val_accuracy: 0.9651\n",
      "Epoch 35/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1978 - accuracy: 0.9240\n",
      "Epoch 35: val_loss did not improve from 0.16414\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1969 - accuracy: 0.9270 - val_loss: 0.1874 - val_accuracy: 0.9554\n",
      "Epoch 36/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1891 - accuracy: 0.9340\n",
      "Epoch 36: val_loss improved from 0.16414 to 0.15434, saving model to ./model\\036-0.1543.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1927 - accuracy: 0.9270 - val_loss: 0.1543 - val_accuracy: 0.9697\n",
      "Epoch 37/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1968 - accuracy: 0.9240\n",
      "Epoch 37: val_loss did not improve from 0.15434\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1897 - accuracy: 0.9292 - val_loss: 0.1638 - val_accuracy: 0.9677\n",
      "Epoch 38/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2071 - accuracy: 0.9220\n",
      "Epoch 38: val_loss improved from 0.15434 to 0.11759, saving model to ./model\\038-0.1176.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1849 - accuracy: 0.9327 - val_loss: 0.1176 - val_accuracy: 0.9774\n",
      "Epoch 39/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1919 - accuracy: 0.9320\n",
      "Epoch 39: val_loss did not improve from 0.11759\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1785 - accuracy: 0.9349 - val_loss: 0.1270 - val_accuracy: 0.9708\n",
      "Epoch 40/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.2009 - accuracy: 0.9340\n",
      "Epoch 40: val_loss improved from 0.11759 to 0.10506, saving model to ./model\\040-0.1051.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1727 - accuracy: 0.9380 - val_loss: 0.1051 - val_accuracy: 0.9815\n",
      "Epoch 41/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1645 - accuracy: 0.9340\n",
      "Epoch 41: val_loss improved from 0.10506 to 0.06299, saving model to ./model\\041-0.0630.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1592 - accuracy: 0.9463 - val_loss: 0.0630 - val_accuracy: 0.9851\n",
      "Epoch 42/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1585 - accuracy: 0.9340\n",
      "Epoch 42: val_loss did not improve from 0.06299\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1519 - accuracy: 0.9448 - val_loss: 0.1504 - val_accuracy: 0.9697\n",
      "Epoch 43/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1623 - accuracy: 0.9540\n",
      "Epoch 43: val_loss did not improve from 0.06299\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1506 - accuracy: 0.9510 - val_loss: 0.0967 - val_accuracy: 0.9790\n",
      "Epoch 44/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1586 - accuracy: 0.9580\n",
      "Epoch 44: val_loss did not improve from 0.06299\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.9496 - val_loss: 0.0715 - val_accuracy: 0.9836\n",
      "Epoch 45/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1328 - accuracy: 0.9500\n",
      "Epoch 45: val_loss did not improve from 0.06299\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1371 - accuracy: 0.9529 - val_loss: 0.0664 - val_accuracy: 0.9862\n",
      "Epoch 46/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1285 - accuracy: 0.9540\n",
      "Epoch 46: val_loss did not improve from 0.06299\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1336 - accuracy: 0.9556 - val_loss: 0.0762 - val_accuracy: 0.9841\n",
      "Epoch 47/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1372 - accuracy: 0.9520\n",
      "Epoch 47: val_loss did not improve from 0.06299\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1347 - accuracy: 0.9549 - val_loss: 0.1323 - val_accuracy: 0.9713\n",
      "Epoch 48/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1109 - accuracy: 0.9700\n",
      "Epoch 48: val_loss did not improve from 0.06299\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1299 - accuracy: 0.9562 - val_loss: 0.0954 - val_accuracy: 0.9785\n",
      "Epoch 49/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1209 - accuracy: 0.9700\n",
      "Epoch 49: val_loss improved from 0.06299 to 0.06094, saving model to ./model\\049-0.0609.hdf5\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1249 - accuracy: 0.9595 - val_loss: 0.0609 - val_accuracy: 0.9856\n",
      "Epoch 50/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0971 - accuracy: 0.9660\n",
      "Epoch 50: val_loss did not improve from 0.06094\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1229 - accuracy: 0.9622 - val_loss: 0.0892 - val_accuracy: 0.9800\n",
      "Epoch 51/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1268 - accuracy: 0.9660\n",
      "Epoch 51: val_loss did not improve from 0.06094\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1241 - accuracy: 0.9600 - val_loss: 0.1254 - val_accuracy: 0.9697\n",
      "Epoch 52/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1479 - accuracy: 0.9580\n",
      "Epoch 52: val_loss did not improve from 0.06094\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1286 - accuracy: 0.9582 - val_loss: 0.1317 - val_accuracy: 0.9672\n",
      "Epoch 53/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1193 - accuracy: 0.9720\n",
      "Epoch 53: val_loss did not improve from 0.06094\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1234 - accuracy: 0.9589 - val_loss: 0.0959 - val_accuracy: 0.9759\n",
      "Epoch 54/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1185 - accuracy: 0.9780\n",
      "Epoch 54: val_loss did not improve from 0.06094\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1148 - accuracy: 0.9661 - val_loss: 0.0691 - val_accuracy: 0.9831\n",
      "Epoch 55/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1192 - accuracy: 0.9620\n",
      "Epoch 55: val_loss did not improve from 0.06094\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.9668 - val_loss: 0.0803 - val_accuracy: 0.9815\n",
      "Epoch 56/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0852 - accuracy: 0.9800\n",
      "Epoch 56: val_loss did not improve from 0.06094\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1121 - accuracy: 0.9675 - val_loss: 0.0757 - val_accuracy: 0.9831\n",
      "Epoch 57/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0905 - accuracy: 0.9800\n",
      "Epoch 57: val_loss improved from 0.06094 to 0.05879, saving model to ./model\\057-0.0588.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1099 - accuracy: 0.9683 - val_loss: 0.0588 - val_accuracy: 0.9877\n",
      "Epoch 58/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0989 - accuracy: 0.9580\n",
      "Epoch 58: val_loss did not improve from 0.05879\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1099 - accuracy: 0.9677 - val_loss: 0.0724 - val_accuracy: 0.9841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1214 - accuracy: 0.9620\n",
      "Epoch 59: val_loss did not improve from 0.05879\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.9683 - val_loss: 0.0746 - val_accuracy: 0.9831\n",
      "Epoch 60/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0909 - accuracy: 0.9740\n",
      "Epoch 60: val_loss did not improve from 0.05879\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1059 - accuracy: 0.9701 - val_loss: 0.0924 - val_accuracy: 0.9759\n",
      "Epoch 61/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1158 - accuracy: 0.9740\n",
      "Epoch 61: val_loss did not improve from 0.05879\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1096 - accuracy: 0.9670 - val_loss: 0.0849 - val_accuracy: 0.9795\n",
      "Epoch 62/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1250 - accuracy: 0.9600\n",
      "Epoch 62: val_loss did not improve from 0.05879\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9699 - val_loss: 0.0919 - val_accuracy: 0.9759\n",
      "Epoch 63/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0955 - accuracy: 0.9640\n",
      "Epoch 63: val_loss did not improve from 0.05879\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9701 - val_loss: 0.0764 - val_accuracy: 0.9841\n",
      "Epoch 64/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0944 - accuracy: 0.9680\n",
      "Epoch 64: val_loss did not improve from 0.05879\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9710 - val_loss: 0.0959 - val_accuracy: 0.9759\n",
      "Epoch 65/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1019 - accuracy: 0.9660\n",
      "Epoch 65: val_loss did not improve from 0.05879\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 0.9699 - val_loss: 0.0958 - val_accuracy: 0.9764\n",
      "Epoch 66/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0802 - accuracy: 0.9760\n",
      "Epoch 66: val_loss improved from 0.05879 to 0.04868, saving model to ./model\\066-0.0487.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1007 - accuracy: 0.9718 - val_loss: 0.0487 - val_accuracy: 0.9897\n",
      "Epoch 67/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1151 - accuracy: 0.9700\n",
      "Epoch 67: val_loss improved from 0.04868 to 0.03924, saving model to ./model\\067-0.0392.hdf5\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1102 - accuracy: 0.9650 - val_loss: 0.0392 - val_accuracy: 0.9938\n",
      "Epoch 68/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1009 - accuracy: 0.9640\n",
      "Epoch 68: val_loss did not improve from 0.03924\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.9670 - val_loss: 0.0514 - val_accuracy: 0.9897\n",
      "Epoch 69/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1209 - accuracy: 0.9640\n",
      "Epoch 69: val_loss did not improve from 0.03924\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9725 - val_loss: 0.0610 - val_accuracy: 0.9887\n",
      "Epoch 70/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1378 - accuracy: 0.9620\n",
      "Epoch 70: val_loss did not improve from 0.03924\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.9743 - val_loss: 0.0803 - val_accuracy: 0.9826\n",
      "Epoch 71/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0687 - accuracy: 0.9860\n",
      "Epoch 71: val_loss did not improve from 0.03924\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9749 - val_loss: 0.0769 - val_accuracy: 0.9841\n",
      "Epoch 72/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0822 - accuracy: 0.9760\n",
      "Epoch 72: val_loss did not improve from 0.03924\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9743 - val_loss: 0.0596 - val_accuracy: 0.9882\n",
      "Epoch 73/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0771 - accuracy: 0.9720\n",
      "Epoch 73: val_loss did not improve from 0.03924\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9734 - val_loss: 0.0663 - val_accuracy: 0.9862\n",
      "Epoch 74/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0803 - accuracy: 0.9760\n",
      "Epoch 74: val_loss did not improve from 0.03924\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0914 - accuracy: 0.9745 - val_loss: 0.0718 - val_accuracy: 0.9856\n",
      "Epoch 75/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0993 - accuracy: 0.9720\n",
      "Epoch 75: val_loss did not improve from 0.03924\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9736 - val_loss: 0.0664 - val_accuracy: 0.9862\n",
      "Epoch 76/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.0862 - accuracy: 0.9800\n",
      "Epoch 76: val_loss did not improve from 0.03924\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9729 - val_loss: 0.0625 - val_accuracy: 0.9882\n",
      "Epoch 77/1000\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1284 - accuracy: 0.9580\n",
      "Epoch 77: val_loss did not improve from 0.03924\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 0.9747 - val_loss: 0.0884 - val_accuracy: 0.9810\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X,Y, validation_split=0.3, epochs=1000,\n",
    "                batch_size=500, verbose=1,\n",
    "                callbacks = [checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "427a638e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], c='r')\n",
    "plt.plot(hist.history['val_loss'], c='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41322fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "\n",
       "       11    12    13  \n",
       "0  396.90  4.98  24.0  \n",
       "1  396.90  9.14  21.6  \n",
       "2  392.83  4.03  34.7  \n",
       "3  394.63  2.94  33.4  \n",
       "4  396.90  5.33  36.2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/housing.csv', delim_whitespace=True, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4accda56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.values[:, :-1].astype(np.float32)\n",
    "Y = df.values[:, -1].astype(np.float32)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55217fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(30, input_dim=13, activation='relu'))\n",
    "model.add(keras.layers.Dense(6, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f2b7b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 30)                420       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 186       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613\n",
      "Trainable params: 613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd92f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam',\n",
    "             metrics='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fb83414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 [==============================] - 1s 23ms/step - loss: 926.4572 - mse: 926.4572 - val_loss: 2144.1267 - val_mse: 2144.1267\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 336.8731 - mse: 336.8731 - val_loss: 3800.1077 - val_mse: 3800.1077\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 287.1517 - mse: 287.1517 - val_loss: 1958.5730 - val_mse: 1958.5730\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 186.6421 - mse: 186.6421 - val_loss: 933.9246 - val_mse: 933.9246\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 161.2706 - mse: 161.2706 - val_loss: 986.5878 - val_mse: 986.5878\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 137.2868 - mse: 137.2868 - val_loss: 901.8921 - val_mse: 901.8921\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 122.4564 - mse: 122.4564 - val_loss: 643.4689 - val_mse: 643.4689\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.7630 - mse: 114.7630 - val_loss: 536.0649 - val_mse: 536.0649\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 104.3225 - mse: 104.3225 - val_loss: 726.1179 - val_mse: 726.1179\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 101.1510 - mse: 101.1510 - val_loss: 677.5384 - val_mse: 677.5384\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 92.8855 - mse: 92.8855 - val_loss: 479.8707 - val_mse: 479.8707\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 85.9893 - mse: 85.9893 - val_loss: 359.9217 - val_mse: 359.9217\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.7186 - mse: 81.7186 - val_loss: 384.5752 - val_mse: 384.5751\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 77.2367 - mse: 77.2367 - val_loss: 383.9339 - val_mse: 383.9340\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.5231 - mse: 74.5231 - val_loss: 431.4574 - val_mse: 431.4574\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.5960 - mse: 71.5960 - val_loss: 543.7451 - val_mse: 543.7451\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 67.6804 - mse: 67.6804 - val_loss: 584.0380 - val_mse: 584.0380\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 64.4090 - mse: 64.4090 - val_loss: 526.1627 - val_mse: 526.1627\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 63.1985 - mse: 63.1985 - val_loss: 571.7488 - val_mse: 571.7488\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.4223 - mse: 60.4223 - val_loss: 594.3592 - val_mse: 594.3592\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X,Y, validation_split=0.3, epochs=20, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "932aa27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mse', 'val_loss', 'val_mse'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7409c3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], c='r')\n",
    "plt.plot(hist.history['val_loss'], c='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f70241ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1966784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape,test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83a9d00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axe = plt.subplots(1,10,figsize=(10,10))\n",
    "\n",
    "for i in range(10):\n",
    "    axe[i].imshow(train_input[i], cmap='gray')\n",
    "    axe[i].axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "538564cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a63bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_scaled_pre = (train_input/255.).reshape(-1, 28*28)\n",
    "test_scaled_pre = (test_input/255.).reshape(-1, 28*28)\n",
    "print(train_scaled_pre.shape, test_scaled_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bb41e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled_pre, train_target, test_size=0.2, stratify=train_target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6250c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784) (48000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_scaled.shape, train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be618169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(100, activation='relu', input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9ae2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             metrics='accuracy',\n",
    "             optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd60feb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.9743 - accuracy: 0.6712 - val_loss: 0.6161 - val_accuracy: 0.7896\n",
      "Epoch 2/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.5573 - accuracy: 0.8103 - val_loss: 0.5158 - val_accuracy: 0.8272\n",
      "Epoch 3/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4881 - accuracy: 0.8341 - val_loss: 0.4723 - val_accuracy: 0.8409\n",
      "Epoch 4/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.4527 - accuracy: 0.8446 - val_loss: 0.4494 - val_accuracy: 0.8499\n",
      "Epoch 5/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4295 - accuracy: 0.8522 - val_loss: 0.4307 - val_accuracy: 0.8526\n",
      "Epoch 6/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4092 - accuracy: 0.8591 - val_loss: 0.4164 - val_accuracy: 0.8597\n",
      "Epoch 7/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.8630 - val_loss: 0.4086 - val_accuracy: 0.8612\n",
      "Epoch 8/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3855 - accuracy: 0.8662 - val_loss: 0.4016 - val_accuracy: 0.8616\n",
      "Epoch 9/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3745 - accuracy: 0.8695 - val_loss: 0.3908 - val_accuracy: 0.8658\n",
      "Epoch 10/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.3637 - accuracy: 0.8722 - val_loss: 0.3813 - val_accuracy: 0.8679\n",
      "Epoch 11/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.8758 - val_loss: 0.3812 - val_accuracy: 0.8653\n",
      "Epoch 12/500\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3486 - accuracy: 0.8778 - val_loss: 0.3791 - val_accuracy: 0.8686\n",
      "Epoch 13/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.3465 - accuracy: 0.8781 - val_loss: 0.3704 - val_accuracy: 0.8721\n",
      "Epoch 14/500\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3360 - accuracy: 0.8817 - val_loss: 0.3677 - val_accuracy: 0.8723\n",
      "Epoch 15/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3312 - accuracy: 0.8829 - val_loss: 0.3666 - val_accuracy: 0.8704\n",
      "Epoch 16/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3266 - accuracy: 0.8850 - val_loss: 0.3552 - val_accuracy: 0.8742\n",
      "Epoch 17/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3209 - accuracy: 0.8865 - val_loss: 0.3527 - val_accuracy: 0.8752\n",
      "Epoch 18/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.3126 - accuracy: 0.8889 - val_loss: 0.3497 - val_accuracy: 0.8773\n",
      "Epoch 19/500\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3088 - accuracy: 0.8893 - val_loss: 0.3498 - val_accuracy: 0.8758\n",
      "Epoch 20/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.3061 - accuracy: 0.8899 - val_loss: 0.3462 - val_accuracy: 0.8773\n",
      "Epoch 21/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3004 - accuracy: 0.8938 - val_loss: 0.3414 - val_accuracy: 0.8762\n",
      "Epoch 22/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2977 - accuracy: 0.8934 - val_loss: 0.3457 - val_accuracy: 0.8790\n",
      "Epoch 23/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2949 - accuracy: 0.8941 - val_loss: 0.3437 - val_accuracy: 0.8785\n",
      "Epoch 24/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2898 - accuracy: 0.8970 - val_loss: 0.3478 - val_accuracy: 0.8745\n",
      "Epoch 25/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2868 - accuracy: 0.8966 - val_loss: 0.3344 - val_accuracy: 0.8775\n",
      "Epoch 26/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2818 - accuracy: 0.8976 - val_loss: 0.3353 - val_accuracy: 0.8805\n",
      "Epoch 27/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2794 - accuracy: 0.8999 - val_loss: 0.3356 - val_accuracy: 0.8773\n",
      "Epoch 28/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2778 - accuracy: 0.9009 - val_loss: 0.3339 - val_accuracy: 0.8784\n",
      "Epoch 29/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2731 - accuracy: 0.9027 - val_loss: 0.3344 - val_accuracy: 0.8765\n",
      "Epoch 30/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2715 - accuracy: 0.9024 - val_loss: 0.3278 - val_accuracy: 0.8810\n",
      "Epoch 31/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2679 - accuracy: 0.9045 - val_loss: 0.3243 - val_accuracy: 0.8820\n",
      "Epoch 32/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2641 - accuracy: 0.9054 - val_loss: 0.3275 - val_accuracy: 0.8809\n",
      "Epoch 33/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2624 - accuracy: 0.9062 - val_loss: 0.3267 - val_accuracy: 0.8811\n",
      "Epoch 34/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2585 - accuracy: 0.9075 - val_loss: 0.3307 - val_accuracy: 0.8815\n",
      "Epoch 35/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2582 - accuracy: 0.9078 - val_loss: 0.3251 - val_accuracy: 0.8809\n",
      "Epoch 36/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2544 - accuracy: 0.9080 - val_loss: 0.3257 - val_accuracy: 0.8825\n",
      "Epoch 37/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2562 - accuracy: 0.9068 - val_loss: 0.3288 - val_accuracy: 0.8808\n",
      "Epoch 38/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2520 - accuracy: 0.9092 - val_loss: 0.3302 - val_accuracy: 0.8857\n",
      "Epoch 39/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2488 - accuracy: 0.9108 - val_loss: 0.3269 - val_accuracy: 0.8823\n",
      "Epoch 40/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2475 - accuracy: 0.9110 - val_loss: 0.3228 - val_accuracy: 0.8838\n",
      "Epoch 41/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2417 - accuracy: 0.9137 - val_loss: 0.3226 - val_accuracy: 0.8833\n",
      "Epoch 42/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2402 - accuracy: 0.9139 - val_loss: 0.3241 - val_accuracy: 0.8845\n",
      "Epoch 43/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2407 - accuracy: 0.9139 - val_loss: 0.3200 - val_accuracy: 0.8848\n",
      "Epoch 44/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.2352 - accuracy: 0.9157 - val_loss: 0.3171 - val_accuracy: 0.8858\n",
      "Epoch 45/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2373 - accuracy: 0.9153 - val_loss: 0.3273 - val_accuracy: 0.8822\n",
      "Epoch 46/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2342 - accuracy: 0.9158 - val_loss: 0.3237 - val_accuracy: 0.8851\n",
      "Epoch 47/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.2326 - accuracy: 0.9169 - val_loss: 0.3284 - val_accuracy: 0.8829\n",
      "Epoch 48/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2294 - accuracy: 0.9173 - val_loss: 0.3175 - val_accuracy: 0.8858\n",
      "Epoch 49/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2266 - accuracy: 0.9187 - val_loss: 0.3268 - val_accuracy: 0.8823\n",
      "Epoch 50/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2271 - accuracy: 0.9181 - val_loss: 0.3219 - val_accuracy: 0.8878\n",
      "Epoch 51/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2269 - accuracy: 0.9187 - val_loss: 0.3211 - val_accuracy: 0.8870\n",
      "Epoch 52/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2200 - accuracy: 0.9214 - val_loss: 0.3235 - val_accuracy: 0.8838\n",
      "Epoch 53/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2199 - accuracy: 0.9216 - val_loss: 0.3176 - val_accuracy: 0.8875\n",
      "Epoch 54/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2183 - accuracy: 0.9227 - val_loss: 0.3181 - val_accuracy: 0.8880\n",
      "Epoch 55/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2137 - accuracy: 0.9240 - val_loss: 0.3200 - val_accuracy: 0.8857\n",
      "Epoch 56/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2132 - accuracy: 0.9233 - val_loss: 0.3221 - val_accuracy: 0.8868\n",
      "Epoch 57/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2118 - accuracy: 0.9239 - val_loss: 0.3205 - val_accuracy: 0.8862\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2099 - accuracy: 0.9251 - val_loss: 0.3243 - val_accuracy: 0.8842\n",
      "Epoch 59/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.2125 - accuracy: 0.9240 - val_loss: 0.3192 - val_accuracy: 0.8867\n",
      "Epoch 60/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2077 - accuracy: 0.9265 - val_loss: 0.3237 - val_accuracy: 0.8847\n",
      "Epoch 61/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2116 - accuracy: 0.9241 - val_loss: 0.3300 - val_accuracy: 0.8846\n",
      "Epoch 62/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2038 - accuracy: 0.9277 - val_loss: 0.3237 - val_accuracy: 0.8887\n",
      "Epoch 63/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.2077 - accuracy: 0.9258 - val_loss: 0.3220 - val_accuracy: 0.8869\n",
      "Epoch 64/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.2064 - accuracy: 0.9264 - val_loss: 0.3262 - val_accuracy: 0.8881\n",
      "Epoch 65/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.2063 - accuracy: 0.9265 - val_loss: 0.3273 - val_accuracy: 0.8826\n",
      "Epoch 66/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.2017 - accuracy: 0.9288 - val_loss: 0.3302 - val_accuracy: 0.8857\n",
      "Epoch 67/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.2005 - accuracy: 0.9287 - val_loss: 0.3180 - val_accuracy: 0.8894\n",
      "Epoch 68/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1934 - accuracy: 0.9323 - val_loss: 0.3186 - val_accuracy: 0.8891\n",
      "Epoch 69/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1945 - accuracy: 0.9316 - val_loss: 0.3257 - val_accuracy: 0.8838\n",
      "Epoch 70/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1941 - accuracy: 0.9321 - val_loss: 0.3205 - val_accuracy: 0.8899\n",
      "Epoch 71/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1913 - accuracy: 0.9325 - val_loss: 0.3204 - val_accuracy: 0.8893\n",
      "Epoch 72/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1891 - accuracy: 0.9332 - val_loss: 0.3289 - val_accuracy: 0.8861\n",
      "Epoch 73/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1900 - accuracy: 0.9333 - val_loss: 0.3284 - val_accuracy: 0.8863\n",
      "Epoch 74/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1853 - accuracy: 0.9347 - val_loss: 0.3216 - val_accuracy: 0.8893\n",
      "Epoch 75/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1839 - accuracy: 0.9359 - val_loss: 0.3250 - val_accuracy: 0.8889\n",
      "Epoch 76/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1843 - accuracy: 0.9350 - val_loss: 0.3216 - val_accuracy: 0.8892\n",
      "Epoch 77/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1824 - accuracy: 0.9370 - val_loss: 0.3274 - val_accuracy: 0.8856\n",
      "Epoch 78/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1811 - accuracy: 0.9373 - val_loss: 0.3222 - val_accuracy: 0.8878\n",
      "Epoch 79/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1821 - accuracy: 0.9369 - val_loss: 0.3350 - val_accuracy: 0.8868\n",
      "Epoch 80/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1783 - accuracy: 0.9386 - val_loss: 0.3238 - val_accuracy: 0.8880\n",
      "Epoch 81/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1792 - accuracy: 0.9377 - val_loss: 0.3257 - val_accuracy: 0.8888\n",
      "Epoch 82/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1769 - accuracy: 0.9386 - val_loss: 0.3293 - val_accuracy: 0.8866\n",
      "Epoch 83/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1831 - accuracy: 0.9357 - val_loss: 0.3607 - val_accuracy: 0.8779\n",
      "Epoch 84/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1780 - accuracy: 0.9379 - val_loss: 0.3496 - val_accuracy: 0.8794\n",
      "Epoch 85/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1769 - accuracy: 0.9372 - val_loss: 0.3370 - val_accuracy: 0.8862\n",
      "Epoch 86/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1752 - accuracy: 0.9384 - val_loss: 0.3304 - val_accuracy: 0.8883\n",
      "Epoch 87/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1748 - accuracy: 0.9395 - val_loss: 0.3321 - val_accuracy: 0.8896\n",
      "Epoch 88/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1738 - accuracy: 0.9394 - val_loss: 0.3282 - val_accuracy: 0.8898\n",
      "Epoch 89/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1717 - accuracy: 0.9406 - val_loss: 0.3301 - val_accuracy: 0.8872\n",
      "Epoch 90/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1670 - accuracy: 0.9419 - val_loss: 0.3336 - val_accuracy: 0.8878\n",
      "Epoch 91/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1662 - accuracy: 0.9432 - val_loss: 0.3299 - val_accuracy: 0.8872\n",
      "Epoch 92/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1662 - accuracy: 0.9423 - val_loss: 0.3317 - val_accuracy: 0.8884\n",
      "Epoch 93/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1645 - accuracy: 0.9437 - val_loss: 0.3312 - val_accuracy: 0.8898\n",
      "Epoch 94/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1636 - accuracy: 0.9432 - val_loss: 0.3293 - val_accuracy: 0.8903\n",
      "Epoch 95/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1633 - accuracy: 0.9439 - val_loss: 0.3412 - val_accuracy: 0.8873\n",
      "Epoch 96/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1640 - accuracy: 0.9440 - val_loss: 0.3387 - val_accuracy: 0.8857\n",
      "Epoch 97/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1633 - accuracy: 0.9441 - val_loss: 0.3387 - val_accuracy: 0.8849\n",
      "Epoch 98/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1622 - accuracy: 0.9444 - val_loss: 0.3383 - val_accuracy: 0.8882\n",
      "Epoch 99/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1592 - accuracy: 0.9460 - val_loss: 0.3352 - val_accuracy: 0.8900\n",
      "Epoch 100/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9471 - val_loss: 0.3431 - val_accuracy: 0.8892\n",
      "Epoch 101/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1574 - accuracy: 0.9458 - val_loss: 0.3383 - val_accuracy: 0.8860\n",
      "Epoch 102/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1581 - accuracy: 0.9454 - val_loss: 0.3405 - val_accuracy: 0.8898\n",
      "Epoch 103/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1562 - accuracy: 0.9458 - val_loss: 0.3370 - val_accuracy: 0.8913\n",
      "Epoch 104/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1513 - accuracy: 0.9489 - val_loss: 0.3366 - val_accuracy: 0.8912\n",
      "Epoch 105/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1520 - accuracy: 0.9487 - val_loss: 0.3348 - val_accuracy: 0.8885\n",
      "Epoch 106/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1513 - accuracy: 0.9482 - val_loss: 0.3360 - val_accuracy: 0.8889\n",
      "Epoch 107/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1484 - accuracy: 0.9496 - val_loss: 0.3372 - val_accuracy: 0.8878\n",
      "Epoch 108/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1478 - accuracy: 0.9499 - val_loss: 0.3464 - val_accuracy: 0.8860\n",
      "Epoch 109/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1494 - accuracy: 0.9496 - val_loss: 0.3413 - val_accuracy: 0.8873\n",
      "Epoch 110/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1511 - accuracy: 0.9486 - val_loss: 0.3414 - val_accuracy: 0.8895\n",
      "Epoch 111/500\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.1441 - accuracy: 0.9517 - val_loss: 0.3409 - val_accuracy: 0.8881\n",
      "Epoch 112/500\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.1455 - accuracy: 0.9511 - val_loss: 0.3410 - val_accuracy: 0.8879\n",
      "Epoch 113/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1428 - accuracy: 0.9524 - val_loss: 0.3473 - val_accuracy: 0.8882\n",
      "Epoch 114/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1449 - accuracy: 0.9504 - val_loss: 0.3430 - val_accuracy: 0.8883\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 10ms/step - loss: 0.1449 - accuracy: 0.9506 - val_loss: 0.3456 - val_accuracy: 0.8883\n",
      "Epoch 116/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1421 - accuracy: 0.9523 - val_loss: 0.3438 - val_accuracy: 0.8882\n",
      "Epoch 117/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1397 - accuracy: 0.9530 - val_loss: 0.3460 - val_accuracy: 0.8871\n",
      "Epoch 118/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1407 - accuracy: 0.9524 - val_loss: 0.3545 - val_accuracy: 0.8872\n",
      "Epoch 119/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1376 - accuracy: 0.9532 - val_loss: 0.3485 - val_accuracy: 0.8878\n",
      "Epoch 120/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.1406 - accuracy: 0.9524 - val_loss: 0.3523 - val_accuracy: 0.8859\n",
      "Epoch 121/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1373 - accuracy: 0.9540 - val_loss: 0.3487 - val_accuracy: 0.8873\n",
      "Epoch 122/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1383 - accuracy: 0.9536 - val_loss: 0.3541 - val_accuracy: 0.8851\n",
      "Epoch 123/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1383 - accuracy: 0.9529 - val_loss: 0.3516 - val_accuracy: 0.8885\n",
      "Epoch 124/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1357 - accuracy: 0.9545 - val_loss: 0.3508 - val_accuracy: 0.8867\n",
      "Epoch 125/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1338 - accuracy: 0.9545 - val_loss: 0.3509 - val_accuracy: 0.8878\n",
      "Epoch 126/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1333 - accuracy: 0.9551 - val_loss: 0.3512 - val_accuracy: 0.8907\n",
      "Epoch 127/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1337 - accuracy: 0.9554 - val_loss: 0.3519 - val_accuracy: 0.8887\n",
      "Epoch 128/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1307 - accuracy: 0.9559 - val_loss: 0.3528 - val_accuracy: 0.8911\n",
      "Epoch 129/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1311 - accuracy: 0.9561 - val_loss: 0.3494 - val_accuracy: 0.8873\n",
      "Epoch 130/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1313 - accuracy: 0.9561 - val_loss: 0.3538 - val_accuracy: 0.8881\n",
      "Epoch 131/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1277 - accuracy: 0.9577 - val_loss: 0.3534 - val_accuracy: 0.8892\n",
      "Epoch 132/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1257 - accuracy: 0.9589 - val_loss: 0.3629 - val_accuracy: 0.8876\n",
      "Epoch 133/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1274 - accuracy: 0.9572 - val_loss: 0.3578 - val_accuracy: 0.8889\n",
      "Epoch 134/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1278 - accuracy: 0.9578 - val_loss: 0.3547 - val_accuracy: 0.8898\n",
      "Epoch 135/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1275 - accuracy: 0.9578 - val_loss: 0.3595 - val_accuracy: 0.8876\n",
      "Epoch 136/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1258 - accuracy: 0.9577 - val_loss: 0.3606 - val_accuracy: 0.8900\n",
      "Epoch 137/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1262 - accuracy: 0.9572 - val_loss: 0.3606 - val_accuracy: 0.8869\n",
      "Epoch 138/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1230 - accuracy: 0.9588 - val_loss: 0.3738 - val_accuracy: 0.8847\n",
      "Epoch 139/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1256 - accuracy: 0.9579 - val_loss: 0.3682 - val_accuracy: 0.8861\n",
      "Epoch 140/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1233 - accuracy: 0.9582 - val_loss: 0.3619 - val_accuracy: 0.8903\n",
      "Epoch 141/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1193 - accuracy: 0.9606 - val_loss: 0.3734 - val_accuracy: 0.8867\n",
      "Epoch 142/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1284 - accuracy: 0.9561 - val_loss: 0.3619 - val_accuracy: 0.8888\n",
      "Epoch 143/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1212 - accuracy: 0.9593 - val_loss: 0.3699 - val_accuracy: 0.8873\n",
      "Epoch 144/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1187 - accuracy: 0.9611 - val_loss: 0.3786 - val_accuracy: 0.8836\n",
      "Epoch 145/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1183 - accuracy: 0.9612 - val_loss: 0.3787 - val_accuracy: 0.8857\n",
      "Epoch 146/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1169 - accuracy: 0.9621 - val_loss: 0.3719 - val_accuracy: 0.8857\n",
      "Epoch 147/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1166 - accuracy: 0.9620 - val_loss: 0.3680 - val_accuracy: 0.8847\n",
      "Epoch 148/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1159 - accuracy: 0.9625 - val_loss: 0.3717 - val_accuracy: 0.8871\n",
      "Epoch 149/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1158 - accuracy: 0.9622 - val_loss: 0.3786 - val_accuracy: 0.8838\n",
      "Epoch 150/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1141 - accuracy: 0.9627 - val_loss: 0.3750 - val_accuracy: 0.8890\n",
      "Epoch 151/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1154 - accuracy: 0.9622 - val_loss: 0.3748 - val_accuracy: 0.8854\n",
      "Epoch 152/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1178 - accuracy: 0.9604 - val_loss: 0.3722 - val_accuracy: 0.8883\n",
      "Epoch 153/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1110 - accuracy: 0.9646 - val_loss: 0.3777 - val_accuracy: 0.8833\n",
      "Epoch 154/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.1133 - accuracy: 0.9628 - val_loss: 0.3747 - val_accuracy: 0.8872\n",
      "Epoch 155/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1121 - accuracy: 0.9637 - val_loss: 0.3829 - val_accuracy: 0.8829\n",
      "Epoch 156/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1116 - accuracy: 0.9630 - val_loss: 0.3797 - val_accuracy: 0.8863\n",
      "Epoch 157/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1078 - accuracy: 0.9646 - val_loss: 0.3819 - val_accuracy: 0.8884\n",
      "Epoch 158/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1085 - accuracy: 0.9642 - val_loss: 0.3815 - val_accuracy: 0.8861\n",
      "Epoch 159/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1074 - accuracy: 0.9661 - val_loss: 0.3828 - val_accuracy: 0.8875\n",
      "Epoch 160/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1088 - accuracy: 0.9644 - val_loss: 0.3939 - val_accuracy: 0.8796\n",
      "Epoch 161/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1062 - accuracy: 0.9657 - val_loss: 0.3806 - val_accuracy: 0.8895\n",
      "Epoch 162/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1074 - accuracy: 0.9652 - val_loss: 0.3922 - val_accuracy: 0.8842\n",
      "Epoch 163/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1095 - accuracy: 0.9644 - val_loss: 0.3858 - val_accuracy: 0.8858\n",
      "Epoch 164/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1044 - accuracy: 0.9660 - val_loss: 0.3865 - val_accuracy: 0.8848\n",
      "Epoch 165/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1094 - accuracy: 0.9635 - val_loss: 0.3959 - val_accuracy: 0.8871\n",
      "Epoch 166/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1037 - accuracy: 0.9664 - val_loss: 0.3886 - val_accuracy: 0.8862\n",
      "Epoch 167/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1028 - accuracy: 0.9680 - val_loss: 0.3885 - val_accuracy: 0.8863\n",
      "Epoch 168/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1046 - accuracy: 0.9660 - val_loss: 0.3897 - val_accuracy: 0.8846\n",
      "Epoch 169/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1018 - accuracy: 0.9669 - val_loss: 0.3880 - val_accuracy: 0.8881\n",
      "Epoch 170/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1016 - accuracy: 0.9674 - val_loss: 0.3908 - val_accuracy: 0.8851\n",
      "Epoch 171/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1004 - accuracy: 0.9681 - val_loss: 0.3843 - val_accuracy: 0.8866\n",
      "Epoch 172/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0995 - accuracy: 0.9688 - val_loss: 0.3938 - val_accuracy: 0.8849\n",
      "Epoch 173/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0990 - accuracy: 0.9690 - val_loss: 0.4008 - val_accuracy: 0.8832\n",
      "Epoch 174/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.1022 - accuracy: 0.9670 - val_loss: 0.3983 - val_accuracy: 0.8873\n",
      "Epoch 175/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.1002 - accuracy: 0.9679 - val_loss: 0.3925 - val_accuracy: 0.8873\n",
      "Epoch 176/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0997 - accuracy: 0.9674 - val_loss: 0.3978 - val_accuracy: 0.8834\n",
      "Epoch 177/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0976 - accuracy: 0.9688 - val_loss: 0.3954 - val_accuracy: 0.8872\n",
      "Epoch 178/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0966 - accuracy: 0.9700 - val_loss: 0.4058 - val_accuracy: 0.8855\n",
      "Epoch 179/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0976 - accuracy: 0.9689 - val_loss: 0.4008 - val_accuracy: 0.8867\n",
      "Epoch 180/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0971 - accuracy: 0.9689 - val_loss: 0.3982 - val_accuracy: 0.8870\n",
      "Epoch 181/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0960 - accuracy: 0.9694 - val_loss: 0.3960 - val_accuracy: 0.8886\n",
      "Epoch 182/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0978 - accuracy: 0.9686 - val_loss: 0.4036 - val_accuracy: 0.8852\n",
      "Epoch 183/500\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0983 - accuracy: 0.9682 - val_loss: 0.4050 - val_accuracy: 0.8878\n",
      "Epoch 184/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0930 - accuracy: 0.9698 - val_loss: 0.4039 - val_accuracy: 0.8853\n",
      "Epoch 185/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0923 - accuracy: 0.9714 - val_loss: 0.4029 - val_accuracy: 0.8848\n",
      "Epoch 186/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0903 - accuracy: 0.9716 - val_loss: 0.4043 - val_accuracy: 0.8890\n",
      "Epoch 187/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0981 - accuracy: 0.9686 - val_loss: 0.4118 - val_accuracy: 0.8857\n",
      "Epoch 188/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0916 - accuracy: 0.9711 - val_loss: 0.4187 - val_accuracy: 0.8825\n",
      "Epoch 189/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0934 - accuracy: 0.9700 - val_loss: 0.4075 - val_accuracy: 0.8868\n",
      "Epoch 190/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0896 - accuracy: 0.9714 - val_loss: 0.4090 - val_accuracy: 0.8886\n",
      "Epoch 191/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0911 - accuracy: 0.9710 - val_loss: 0.4134 - val_accuracy: 0.8858\n",
      "Epoch 192/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0888 - accuracy: 0.9717 - val_loss: 0.4085 - val_accuracy: 0.8859\n",
      "Epoch 193/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0902 - accuracy: 0.9713 - val_loss: 0.4133 - val_accuracy: 0.8868\n",
      "Epoch 194/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0914 - accuracy: 0.9709 - val_loss: 0.4148 - val_accuracy: 0.8836\n",
      "Epoch 195/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0898 - accuracy: 0.9710 - val_loss: 0.4172 - val_accuracy: 0.8834\n",
      "Epoch 196/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0899 - accuracy: 0.9711 - val_loss: 0.4209 - val_accuracy: 0.8851\n",
      "Epoch 197/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0887 - accuracy: 0.9712 - val_loss: 0.4100 - val_accuracy: 0.8864\n",
      "Epoch 198/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0861 - accuracy: 0.9732 - val_loss: 0.4226 - val_accuracy: 0.8840\n",
      "Epoch 199/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0864 - accuracy: 0.9725 - val_loss: 0.4198 - val_accuracy: 0.8870\n",
      "Epoch 200/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0854 - accuracy: 0.9735 - val_loss: 0.4151 - val_accuracy: 0.8870\n",
      "Epoch 201/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0835 - accuracy: 0.9749 - val_loss: 0.4170 - val_accuracy: 0.8843\n",
      "Epoch 202/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0856 - accuracy: 0.9732 - val_loss: 0.4257 - val_accuracy: 0.8855\n",
      "Epoch 203/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0838 - accuracy: 0.9736 - val_loss: 0.4212 - val_accuracy: 0.8831\n",
      "Epoch 204/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0831 - accuracy: 0.9742 - val_loss: 0.4259 - val_accuracy: 0.8859\n",
      "Epoch 205/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0826 - accuracy: 0.9742 - val_loss: 0.4291 - val_accuracy: 0.8814\n",
      "Epoch 206/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0861 - accuracy: 0.9729 - val_loss: 0.4236 - val_accuracy: 0.8852\n",
      "Epoch 207/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0807 - accuracy: 0.9752 - val_loss: 0.4352 - val_accuracy: 0.8817\n",
      "Epoch 208/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9744 - val_loss: 0.4335 - val_accuracy: 0.8880\n",
      "Epoch 209/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0822 - accuracy: 0.9746 - val_loss: 0.4261 - val_accuracy: 0.8852\n",
      "Epoch 210/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0819 - accuracy: 0.9743 - val_loss: 0.4287 - val_accuracy: 0.8873\n",
      "Epoch 211/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0855 - accuracy: 0.9724 - val_loss: 0.4316 - val_accuracy: 0.8831\n",
      "Epoch 212/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0796 - accuracy: 0.9756 - val_loss: 0.4318 - val_accuracy: 0.8873\n",
      "Epoch 213/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0798 - accuracy: 0.9756 - val_loss: 0.4422 - val_accuracy: 0.8781\n",
      "Epoch 214/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0801 - accuracy: 0.9749 - val_loss: 0.4324 - val_accuracy: 0.8848\n",
      "Epoch 215/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0782 - accuracy: 0.9761 - val_loss: 0.4340 - val_accuracy: 0.8851\n",
      "Epoch 216/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0794 - accuracy: 0.9753 - val_loss: 0.4392 - val_accuracy: 0.8863\n",
      "Epoch 217/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0774 - accuracy: 0.9760 - val_loss: 0.4455 - val_accuracy: 0.8812\n",
      "Epoch 218/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0766 - accuracy: 0.9765 - val_loss: 0.4384 - val_accuracy: 0.8857\n",
      "Epoch 219/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0740 - accuracy: 0.9781 - val_loss: 0.4356 - val_accuracy: 0.8863\n",
      "Epoch 220/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0762 - accuracy: 0.9766 - val_loss: 0.4396 - val_accuracy: 0.8842\n",
      "Epoch 221/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0750 - accuracy: 0.9781 - val_loss: 0.4439 - val_accuracy: 0.8829\n",
      "Epoch 222/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0778 - accuracy: 0.9761 - val_loss: 0.4404 - val_accuracy: 0.8869\n",
      "Epoch 223/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0768 - accuracy: 0.9762 - val_loss: 0.4667 - val_accuracy: 0.8830\n",
      "Epoch 224/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0760 - accuracy: 0.9771 - val_loss: 0.4493 - val_accuracy: 0.8848\n",
      "Epoch 225/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0756 - accuracy: 0.9760 - val_loss: 0.4467 - val_accuracy: 0.8827\n",
      "Epoch 226/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0758 - accuracy: 0.9761 - val_loss: 0.4482 - val_accuracy: 0.8854\n",
      "Epoch 227/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0764 - accuracy: 0.9766 - val_loss: 0.4520 - val_accuracy: 0.8828\n",
      "Epoch 228/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0734 - accuracy: 0.9772 - val_loss: 0.4544 - val_accuracy: 0.8820\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0761 - accuracy: 0.9757 - val_loss: 0.4542 - val_accuracy: 0.8827\n",
      "Epoch 230/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0725 - accuracy: 0.9780 - val_loss: 0.4585 - val_accuracy: 0.8844\n",
      "Epoch 231/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0731 - accuracy: 0.9778 - val_loss: 0.4647 - val_accuracy: 0.8799\n",
      "Epoch 232/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0739 - accuracy: 0.9765 - val_loss: 0.4614 - val_accuracy: 0.8849\n",
      "Epoch 233/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0712 - accuracy: 0.9783 - val_loss: 0.4646 - val_accuracy: 0.8804\n",
      "Epoch 234/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0700 - accuracy: 0.9792 - val_loss: 0.4609 - val_accuracy: 0.8822\n",
      "Epoch 235/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0733 - accuracy: 0.9773 - val_loss: 0.4684 - val_accuracy: 0.8789\n",
      "Epoch 236/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0709 - accuracy: 0.9781 - val_loss: 0.4526 - val_accuracy: 0.8838\n",
      "Epoch 237/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0687 - accuracy: 0.9792 - val_loss: 0.4550 - val_accuracy: 0.8863\n",
      "Epoch 238/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0669 - accuracy: 0.9808 - val_loss: 0.4660 - val_accuracy: 0.8845\n",
      "Epoch 239/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0699 - accuracy: 0.9780 - val_loss: 0.4607 - val_accuracy: 0.8846\n",
      "Epoch 240/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0743 - accuracy: 0.9764 - val_loss: 0.4708 - val_accuracy: 0.8831\n",
      "Epoch 241/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0669 - accuracy: 0.9812 - val_loss: 0.4645 - val_accuracy: 0.8847\n",
      "Epoch 242/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0701 - accuracy: 0.9778 - val_loss: 0.4683 - val_accuracy: 0.8827\n",
      "Epoch 243/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0680 - accuracy: 0.9786 - val_loss: 0.4715 - val_accuracy: 0.8857\n",
      "Epoch 244/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0677 - accuracy: 0.9796 - val_loss: 0.4716 - val_accuracy: 0.8860\n",
      "Epoch 245/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0673 - accuracy: 0.9791 - val_loss: 0.4773 - val_accuracy: 0.8808\n",
      "Epoch 246/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0656 - accuracy: 0.9801 - val_loss: 0.4655 - val_accuracy: 0.8850\n",
      "Epoch 247/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0643 - accuracy: 0.9810 - val_loss: 0.4774 - val_accuracy: 0.8822\n",
      "Epoch 248/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0658 - accuracy: 0.9807 - val_loss: 0.4676 - val_accuracy: 0.8851\n",
      "Epoch 249/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0644 - accuracy: 0.9808 - val_loss: 0.4767 - val_accuracy: 0.8827\n",
      "Epoch 250/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0653 - accuracy: 0.9801 - val_loss: 0.4857 - val_accuracy: 0.8803\n",
      "Epoch 251/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0690 - accuracy: 0.9781 - val_loss: 0.4831 - val_accuracy: 0.8842\n",
      "Epoch 252/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0659 - accuracy: 0.9800 - val_loss: 0.4755 - val_accuracy: 0.8841\n",
      "Epoch 253/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0654 - accuracy: 0.9801 - val_loss: 0.4807 - val_accuracy: 0.8819\n",
      "Epoch 254/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0658 - accuracy: 0.9798 - val_loss: 0.4773 - val_accuracy: 0.8841\n",
      "Epoch 255/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0620 - accuracy: 0.9816 - val_loss: 0.4843 - val_accuracy: 0.8830\n",
      "Epoch 256/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0616 - accuracy: 0.9818 - val_loss: 0.4805 - val_accuracy: 0.8853\n",
      "Epoch 257/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0636 - accuracy: 0.9812 - val_loss: 0.4845 - val_accuracy: 0.8822\n",
      "Epoch 258/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0619 - accuracy: 0.9819 - val_loss: 0.4846 - val_accuracy: 0.8833\n",
      "Epoch 259/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0649 - accuracy: 0.9799 - val_loss: 0.4969 - val_accuracy: 0.8846\n",
      "Epoch 260/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0629 - accuracy: 0.9809 - val_loss: 0.4952 - val_accuracy: 0.8807\n",
      "Epoch 261/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0601 - accuracy: 0.9826 - val_loss: 0.4878 - val_accuracy: 0.8828\n",
      "Epoch 262/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0616 - accuracy: 0.9818 - val_loss: 0.4915 - val_accuracy: 0.8823\n",
      "Epoch 263/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0609 - accuracy: 0.9815 - val_loss: 0.4846 - val_accuracy: 0.8834\n",
      "Epoch 264/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0587 - accuracy: 0.9832 - val_loss: 0.4884 - val_accuracy: 0.8850\n",
      "Epoch 265/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0612 - accuracy: 0.9816 - val_loss: 0.5051 - val_accuracy: 0.8767\n",
      "Epoch 266/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0593 - accuracy: 0.9820 - val_loss: 0.4943 - val_accuracy: 0.8829\n",
      "Epoch 267/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0594 - accuracy: 0.9823 - val_loss: 0.5000 - val_accuracy: 0.8832\n",
      "Epoch 268/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0567 - accuracy: 0.9843 - val_loss: 0.4939 - val_accuracy: 0.8813\n",
      "Epoch 269/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0572 - accuracy: 0.9837 - val_loss: 0.4976 - val_accuracy: 0.8823\n",
      "Epoch 270/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0573 - accuracy: 0.9837 - val_loss: 0.4957 - val_accuracy: 0.8835\n",
      "Epoch 271/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0559 - accuracy: 0.9841 - val_loss: 0.4974 - val_accuracy: 0.8822\n",
      "Epoch 272/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0571 - accuracy: 0.9831 - val_loss: 0.4945 - val_accuracy: 0.8842\n",
      "Epoch 273/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 0.5065 - val_accuracy: 0.8801\n",
      "Epoch 274/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0607 - accuracy: 0.9813 - val_loss: 0.5052 - val_accuracy: 0.8822\n",
      "Epoch 275/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0570 - accuracy: 0.9835 - val_loss: 0.5077 - val_accuracy: 0.8843\n",
      "Epoch 276/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0550 - accuracy: 0.9841 - val_loss: 0.5074 - val_accuracy: 0.8827\n",
      "Epoch 277/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0561 - accuracy: 0.9839 - val_loss: 0.4996 - val_accuracy: 0.8851\n",
      "Epoch 278/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0541 - accuracy: 0.9847 - val_loss: 0.5021 - val_accuracy: 0.8820\n",
      "Epoch 279/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0536 - accuracy: 0.9852 - val_loss: 0.5063 - val_accuracy: 0.8814\n",
      "Epoch 280/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0579 - accuracy: 0.9825 - val_loss: 0.5095 - val_accuracy: 0.8840\n",
      "Epoch 281/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0538 - accuracy: 0.9851 - val_loss: 0.5122 - val_accuracy: 0.8830\n",
      "Epoch 282/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9836 - val_loss: 0.5171 - val_accuracy: 0.8804\n",
      "Epoch 283/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0552 - accuracy: 0.9844 - val_loss: 0.5150 - val_accuracy: 0.8797\n",
      "Epoch 284/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0531 - accuracy: 0.9843 - val_loss: 0.5136 - val_accuracy: 0.8820\n",
      "Epoch 285/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0556 - accuracy: 0.9840 - val_loss: 0.5199 - val_accuracy: 0.8804\n",
      "Epoch 286/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 0.9833 - val_loss: 0.5196 - val_accuracy: 0.8801\n",
      "Epoch 287/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0526 - accuracy: 0.9849 - val_loss: 0.5257 - val_accuracy: 0.8832\n",
      "Epoch 288/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0514 - accuracy: 0.9851 - val_loss: 0.5184 - val_accuracy: 0.8804\n",
      "Epoch 289/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0541 - accuracy: 0.9843 - val_loss: 0.5206 - val_accuracy: 0.8835\n",
      "Epoch 290/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0513 - accuracy: 0.9852 - val_loss: 0.5276 - val_accuracy: 0.8823\n",
      "Epoch 291/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0556 - accuracy: 0.9835 - val_loss: 0.5272 - val_accuracy: 0.8846\n",
      "Epoch 292/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 0.9852 - val_loss: 0.5227 - val_accuracy: 0.8846\n",
      "Epoch 293/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.5401 - val_accuracy: 0.8798\n",
      "Epoch 294/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0494 - accuracy: 0.9860 - val_loss: 0.5188 - val_accuracy: 0.8832\n",
      "Epoch 295/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0526 - accuracy: 0.9847 - val_loss: 0.5311 - val_accuracy: 0.8823\n",
      "Epoch 296/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0510 - accuracy: 0.9858 - val_loss: 0.5439 - val_accuracy: 0.8789\n",
      "Epoch 297/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0518 - accuracy: 0.9848 - val_loss: 0.5282 - val_accuracy: 0.8803\n",
      "Epoch 298/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0515 - accuracy: 0.9849 - val_loss: 0.5346 - val_accuracy: 0.8811\n",
      "Epoch 299/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0485 - accuracy: 0.9865 - val_loss: 0.5419 - val_accuracy: 0.8792\n",
      "Epoch 300/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0515 - accuracy: 0.9847 - val_loss: 0.5294 - val_accuracy: 0.8806\n",
      "Epoch 301/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0488 - accuracy: 0.9865 - val_loss: 0.5366 - val_accuracy: 0.8814\n",
      "Epoch 302/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0494 - accuracy: 0.9856 - val_loss: 0.5438 - val_accuracy: 0.8804\n",
      "Epoch 303/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0483 - accuracy: 0.9864 - val_loss: 0.5366 - val_accuracy: 0.8803\n",
      "Epoch 304/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0462 - accuracy: 0.9878 - val_loss: 0.5419 - val_accuracy: 0.8808\n",
      "Epoch 305/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0459 - accuracy: 0.9879 - val_loss: 0.5337 - val_accuracy: 0.8827\n",
      "Epoch 306/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0440 - accuracy: 0.9888 - val_loss: 0.5365 - val_accuracy: 0.8804\n",
      "Epoch 307/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0463 - accuracy: 0.9877 - val_loss: 0.5385 - val_accuracy: 0.8811\n",
      "Epoch 308/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0489 - accuracy: 0.9855 - val_loss: 0.5442 - val_accuracy: 0.8817\n",
      "Epoch 309/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9885 - val_loss: 0.5599 - val_accuracy: 0.8761\n",
      "Epoch 310/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0499 - accuracy: 0.9845 - val_loss: 0.5478 - val_accuracy: 0.8800\n",
      "Epoch 311/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0487 - accuracy: 0.9859 - val_loss: 0.5436 - val_accuracy: 0.8828\n",
      "Epoch 312/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0440 - accuracy: 0.9884 - val_loss: 0.5553 - val_accuracy: 0.8818\n",
      "Epoch 313/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0468 - accuracy: 0.9868 - val_loss: 0.5488 - val_accuracy: 0.8806\n",
      "Epoch 314/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9888 - val_loss: 0.5518 - val_accuracy: 0.8818\n",
      "Epoch 315/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9877 - val_loss: 0.5511 - val_accuracy: 0.8797\n",
      "Epoch 316/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 0.9890 - val_loss: 0.5625 - val_accuracy: 0.8773\n",
      "Epoch 317/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0411 - accuracy: 0.9900 - val_loss: 0.5530 - val_accuracy: 0.8793\n",
      "Epoch 318/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0443 - accuracy: 0.9879 - val_loss: 0.5565 - val_accuracy: 0.8833\n",
      "Epoch 319/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9888 - val_loss: 0.5572 - val_accuracy: 0.8814\n",
      "Epoch 320/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0450 - accuracy: 0.9875 - val_loss: 0.5563 - val_accuracy: 0.8808\n",
      "Epoch 321/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0430 - accuracy: 0.9885 - val_loss: 0.5552 - val_accuracy: 0.8843\n",
      "Epoch 322/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9878 - val_loss: 0.5621 - val_accuracy: 0.8802\n",
      "Epoch 323/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 0.9877 - val_loss: 0.5599 - val_accuracy: 0.8804\n",
      "Epoch 324/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0433 - accuracy: 0.9883 - val_loss: 0.5705 - val_accuracy: 0.8836\n",
      "Epoch 325/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9881 - val_loss: 0.5785 - val_accuracy: 0.8758\n",
      "Epoch 326/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0438 - accuracy: 0.9882 - val_loss: 0.5739 - val_accuracy: 0.8787\n",
      "Epoch 327/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9881 - val_loss: 0.5705 - val_accuracy: 0.8798\n",
      "Epoch 328/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9898 - val_loss: 0.5650 - val_accuracy: 0.8795\n",
      "Epoch 329/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9889 - val_loss: 0.5751 - val_accuracy: 0.8795\n",
      "Epoch 330/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0408 - accuracy: 0.9892 - val_loss: 0.5769 - val_accuracy: 0.8785\n",
      "Epoch 331/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0446 - accuracy: 0.9872 - val_loss: 0.5782 - val_accuracy: 0.8786\n",
      "Epoch 332/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0402 - accuracy: 0.9896 - val_loss: 0.5709 - val_accuracy: 0.8809\n",
      "Epoch 333/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0399 - accuracy: 0.9893 - val_loss: 0.5787 - val_accuracy: 0.8794\n",
      "Epoch 334/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9893 - val_loss: 0.5802 - val_accuracy: 0.8796\n",
      "Epoch 335/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0421 - accuracy: 0.9879 - val_loss: 0.5761 - val_accuracy: 0.8792\n",
      "Epoch 336/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0403 - accuracy: 0.9892 - val_loss: 0.5828 - val_accuracy: 0.8812\n",
      "Epoch 337/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0389 - accuracy: 0.9898 - val_loss: 0.5803 - val_accuracy: 0.8817\n",
      "Epoch 338/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0398 - accuracy: 0.9894 - val_loss: 0.5855 - val_accuracy: 0.8805\n",
      "Epoch 339/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9891 - val_loss: 0.5905 - val_accuracy: 0.8782\n",
      "Epoch 340/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0395 - accuracy: 0.9896 - val_loss: 0.5857 - val_accuracy: 0.8807\n",
      "Epoch 341/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0374 - accuracy: 0.9905 - val_loss: 0.5866 - val_accuracy: 0.8789\n",
      "Epoch 342/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0377 - accuracy: 0.9902 - val_loss: 0.5865 - val_accuracy: 0.8813\n",
      "Epoch 343/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0410 - accuracy: 0.9880 - val_loss: 0.5878 - val_accuracy: 0.8801\n",
      "Epoch 344/500\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.0386 - accuracy: 0.9900 - val_loss: 0.5894 - val_accuracy: 0.8796\n",
      "Epoch 345/500\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0357 - accuracy: 0.9916 - val_loss: 0.5908 - val_accuracy: 0.8805\n",
      "Epoch 346/500\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0396 - accuracy: 0.9890 - val_loss: 0.6046 - val_accuracy: 0.8743\n",
      "Epoch 347/500\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0387 - accuracy: 0.9890 - val_loss: 0.5888 - val_accuracy: 0.8816\n",
      "Epoch 348/500\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.5967 - val_accuracy: 0.8820\n",
      "Epoch 349/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0355 - accuracy: 0.9915 - val_loss: 0.5881 - val_accuracy: 0.8804\n",
      "Epoch 350/500\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0383 - accuracy: 0.9896 - val_loss: 0.5923 - val_accuracy: 0.8812\n",
      "Epoch 351/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0372 - accuracy: 0.9901 - val_loss: 0.5991 - val_accuracy: 0.8797\n",
      "Epoch 352/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9908 - val_loss: 0.5979 - val_accuracy: 0.8804\n",
      "Epoch 353/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0352 - accuracy: 0.9914 - val_loss: 0.6010 - val_accuracy: 0.8789\n",
      "Epoch 354/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0374 - accuracy: 0.9901 - val_loss: 0.6056 - val_accuracy: 0.8779\n",
      "Epoch 355/500\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0336 - accuracy: 0.9923 - val_loss: 0.5975 - val_accuracy: 0.8801\n",
      "Epoch 356/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0341 - accuracy: 0.9916 - val_loss: 0.6004 - val_accuracy: 0.8809\n",
      "Epoch 357/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0354 - accuracy: 0.9907 - val_loss: 0.6139 - val_accuracy: 0.8764\n",
      "Epoch 358/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0387 - accuracy: 0.9888 - val_loss: 0.6070 - val_accuracy: 0.8790\n",
      "Epoch 359/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0423 - accuracy: 0.9868 - val_loss: 0.6181 - val_accuracy: 0.8788\n",
      "Epoch 360/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0359 - accuracy: 0.9904 - val_loss: 0.6105 - val_accuracy: 0.8817\n",
      "Epoch 361/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 0.6103 - val_accuracy: 0.8811\n",
      "Epoch 362/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0329 - accuracy: 0.9923 - val_loss: 0.6080 - val_accuracy: 0.8820\n",
      "Epoch 363/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 0.9922 - val_loss: 0.6134 - val_accuracy: 0.8801\n",
      "Epoch 364/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0307 - accuracy: 0.9930 - val_loss: 0.6173 - val_accuracy: 0.8808\n",
      "Epoch 365/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0341 - accuracy: 0.9913 - val_loss: 0.6171 - val_accuracy: 0.8803\n",
      "Epoch 366/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0333 - accuracy: 0.9918 - val_loss: 0.6463 - val_accuracy: 0.8723\n",
      "Epoch 367/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 0.9896 - val_loss: 0.6214 - val_accuracy: 0.8787\n",
      "Epoch 368/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0312 - accuracy: 0.9927 - val_loss: 0.6225 - val_accuracy: 0.8788\n",
      "Epoch 369/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0313 - accuracy: 0.9929 - val_loss: 0.6194 - val_accuracy: 0.8794\n",
      "Epoch 370/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 0.9881 - val_loss: 0.6303 - val_accuracy: 0.8763\n",
      "Epoch 371/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 0.9917 - val_loss: 0.6327 - val_accuracy: 0.8797\n",
      "Epoch 372/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0347 - accuracy: 0.9905 - val_loss: 0.6413 - val_accuracy: 0.8744\n",
      "Epoch 373/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9909 - val_loss: 0.6295 - val_accuracy: 0.8791\n",
      "Epoch 374/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0307 - accuracy: 0.9928 - val_loss: 0.6257 - val_accuracy: 0.8788\n",
      "Epoch 375/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0307 - accuracy: 0.9928 - val_loss: 0.6353 - val_accuracy: 0.8806\n",
      "Epoch 376/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0322 - accuracy: 0.9916 - val_loss: 0.6426 - val_accuracy: 0.8789\n",
      "Epoch 377/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.9922 - val_loss: 0.6254 - val_accuracy: 0.8804\n",
      "Epoch 378/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0313 - accuracy: 0.9924 - val_loss: 0.6301 - val_accuracy: 0.8788\n",
      "Epoch 379/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 0.9935 - val_loss: 0.6338 - val_accuracy: 0.8815\n",
      "Epoch 380/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0324 - accuracy: 0.9918 - val_loss: 0.6478 - val_accuracy: 0.8763\n",
      "Epoch 381/500\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.0308 - accuracy: 0.9929 - val_loss: 0.6568 - val_accuracy: 0.8741\n",
      "Epoch 382/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0292 - accuracy: 0.9936 - val_loss: 0.6460 - val_accuracy: 0.8788\n",
      "Epoch 383/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.9937 - val_loss: 0.6404 - val_accuracy: 0.8796\n",
      "Epoch 384/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.9942 - val_loss: 0.6375 - val_accuracy: 0.8792\n",
      "Epoch 385/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9933 - val_loss: 0.6450 - val_accuracy: 0.8781\n",
      "Epoch 386/500\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.0297 - accuracy: 0.9929 - val_loss: 0.6454 - val_accuracy: 0.8802\n",
      "Epoch 387/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9932 - val_loss: 0.6468 - val_accuracy: 0.8783\n",
      "Epoch 388/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9907 - val_loss: 0.6551 - val_accuracy: 0.8801\n",
      "Epoch 389/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0351 - accuracy: 0.9905 - val_loss: 0.6636 - val_accuracy: 0.8752\n",
      "Epoch 390/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0323 - accuracy: 0.9915 - val_loss: 0.6621 - val_accuracy: 0.8767\n",
      "Epoch 391/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 0.9932 - val_loss: 0.6589 - val_accuracy: 0.8793\n",
      "Epoch 392/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9940 - val_loss: 0.6665 - val_accuracy: 0.8767\n",
      "Epoch 393/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0317 - accuracy: 0.9916 - val_loss: 0.6521 - val_accuracy: 0.8801\n",
      "Epoch 394/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9927 - val_loss: 0.6600 - val_accuracy: 0.8784\n",
      "Epoch 395/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0310 - accuracy: 0.9919 - val_loss: 0.6686 - val_accuracy: 0.8793\n",
      "Epoch 396/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.6635 - val_accuracy: 0.8814\n",
      "Epoch 397/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0351 - accuracy: 0.9893 - val_loss: 0.6523 - val_accuracy: 0.8783\n",
      "Epoch 398/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 0.9935 - val_loss: 0.6612 - val_accuracy: 0.8770\n",
      "Epoch 399/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9939 - val_loss: 0.6614 - val_accuracy: 0.8804\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9935 - val_loss: 0.6523 - val_accuracy: 0.8808\n",
      "Epoch 401/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9944 - val_loss: 0.6687 - val_accuracy: 0.8788\n",
      "Epoch 402/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9942 - val_loss: 0.6634 - val_accuracy: 0.8802\n",
      "Epoch 403/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0275 - accuracy: 0.9934 - val_loss: 0.6564 - val_accuracy: 0.8776\n",
      "Epoch 404/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9952 - val_loss: 0.6661 - val_accuracy: 0.8788\n",
      "Epoch 405/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9950 - val_loss: 0.6628 - val_accuracy: 0.8787\n",
      "Epoch 406/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9949 - val_loss: 0.6646 - val_accuracy: 0.8802\n",
      "Epoch 407/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0241 - accuracy: 0.9949 - val_loss: 0.6646 - val_accuracy: 0.8795\n",
      "Epoch 408/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9947 - val_loss: 0.6637 - val_accuracy: 0.8791\n",
      "Epoch 409/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0293 - accuracy: 0.9923 - val_loss: 0.6658 - val_accuracy: 0.8806\n",
      "Epoch 410/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9933 - val_loss: 0.6719 - val_accuracy: 0.8794\n",
      "Epoch 411/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9946 - val_loss: 0.6708 - val_accuracy: 0.8779\n",
      "Epoch 412/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0238 - accuracy: 0.9952 - val_loss: 0.6799 - val_accuracy: 0.8772\n",
      "Epoch 413/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.9924 - val_loss: 0.6733 - val_accuracy: 0.8800\n",
      "Epoch 414/500\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 0.9948 - val_loss: 0.6774 - val_accuracy: 0.8792\n",
      "Epoch 415/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.6790 - val_accuracy: 0.8790\n",
      "Epoch 416/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9957 - val_loss: 0.6768 - val_accuracy: 0.8775\n",
      "Epoch 417/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9949 - val_loss: 0.6746 - val_accuracy: 0.8802\n",
      "Epoch 418/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9930 - val_loss: 0.6789 - val_accuracy: 0.8792\n",
      "Epoch 419/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0239 - accuracy: 0.9947 - val_loss: 0.6836 - val_accuracy: 0.8769\n",
      "Epoch 420/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9952 - val_loss: 0.6909 - val_accuracy: 0.8795\n",
      "Epoch 421/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9945 - val_loss: 0.6849 - val_accuracy: 0.8779\n",
      "Epoch 422/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 0.9929 - val_loss: 0.6921 - val_accuracy: 0.8811\n",
      "Epoch 423/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.6791 - val_accuracy: 0.8790\n",
      "Epoch 424/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9946 - val_loss: 0.6898 - val_accuracy: 0.8786\n",
      "Epoch 425/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0231 - accuracy: 0.9951 - val_loss: 0.6988 - val_accuracy: 0.8764\n",
      "Epoch 426/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9956 - val_loss: 0.6877 - val_accuracy: 0.8766\n",
      "Epoch 427/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9946 - val_loss: 0.7217 - val_accuracy: 0.8718\n",
      "Epoch 428/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.9924 - val_loss: 0.6904 - val_accuracy: 0.8788\n",
      "Epoch 429/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0246 - accuracy: 0.9942 - val_loss: 0.6949 - val_accuracy: 0.8789\n",
      "Epoch 430/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0270 - accuracy: 0.9930 - val_loss: 0.6840 - val_accuracy: 0.8798\n",
      "Epoch 431/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.9938 - val_loss: 0.6950 - val_accuracy: 0.8786\n",
      "Epoch 432/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 0.9956 - val_loss: 0.6978 - val_accuracy: 0.8778\n",
      "Epoch 433/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9961 - val_loss: 0.7099 - val_accuracy: 0.8758\n",
      "Epoch 434/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9945 - val_loss: 0.6979 - val_accuracy: 0.8785\n",
      "Epoch 435/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0204 - accuracy: 0.9960 - val_loss: 0.7191 - val_accuracy: 0.8737\n",
      "Epoch 436/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 0.6984 - val_accuracy: 0.8777\n",
      "Epoch 437/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9963 - val_loss: 0.7003 - val_accuracy: 0.8766\n",
      "Epoch 438/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9939 - val_loss: 0.7181 - val_accuracy: 0.8756\n",
      "Epoch 439/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0210 - accuracy: 0.9958 - val_loss: 0.7039 - val_accuracy: 0.8753\n",
      "Epoch 440/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0282 - accuracy: 0.9924 - val_loss: 0.7377 - val_accuracy: 0.8791\n",
      "Epoch 441/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9934 - val_loss: 0.7111 - val_accuracy: 0.8789\n",
      "Epoch 442/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9955 - val_loss: 0.7077 - val_accuracy: 0.8794\n",
      "Epoch 443/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0192 - accuracy: 0.9965 - val_loss: 0.7131 - val_accuracy: 0.8772\n",
      "Epoch 444/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0197 - accuracy: 0.9965 - val_loss: 0.7176 - val_accuracy: 0.8783\n",
      "Epoch 445/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9947 - val_loss: 0.7130 - val_accuracy: 0.8785\n",
      "Epoch 446/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9955 - val_loss: 0.7239 - val_accuracy: 0.8770\n",
      "Epoch 447/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.7137 - val_accuracy: 0.8788\n",
      "Epoch 448/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0203 - accuracy: 0.9960 - val_loss: 0.7219 - val_accuracy: 0.8806\n",
      "Epoch 449/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0203 - accuracy: 0.9962 - val_loss: 0.7165 - val_accuracy: 0.8772\n",
      "Epoch 450/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 0.9967 - val_loss: 0.7169 - val_accuracy: 0.8775\n",
      "Epoch 451/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 0.9971 - val_loss: 0.7278 - val_accuracy: 0.8783\n",
      "Epoch 452/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.7231 - val_accuracy: 0.8802\n",
      "Epoch 453/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0244 - accuracy: 0.9937 - val_loss: 0.7251 - val_accuracy: 0.8777\n",
      "Epoch 454/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9944 - val_loss: 0.7369 - val_accuracy: 0.8743\n",
      "Epoch 455/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0190 - accuracy: 0.9965 - val_loss: 0.7233 - val_accuracy: 0.8783\n",
      "Epoch 456/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0193 - accuracy: 0.9965 - val_loss: 0.7337 - val_accuracy: 0.8771\n",
      "Epoch 457/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0171 - accuracy: 0.9975 - val_loss: 0.7215 - val_accuracy: 0.8775\n",
      "Epoch 458/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0171 - accuracy: 0.9972 - val_loss: 0.7330 - val_accuracy: 0.8744\n",
      "Epoch 459/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0180 - accuracy: 0.9969 - val_loss: 0.7383 - val_accuracy: 0.8787\n",
      "Epoch 460/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 0.7282 - val_accuracy: 0.8778\n",
      "Epoch 461/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 0.9961 - val_loss: 0.7249 - val_accuracy: 0.8788\n",
      "Epoch 462/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0201 - accuracy: 0.9956 - val_loss: 0.7337 - val_accuracy: 0.8767\n",
      "Epoch 463/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 0.9974 - val_loss: 0.7350 - val_accuracy: 0.8788\n",
      "Epoch 464/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9964 - val_loss: 0.7352 - val_accuracy: 0.8775\n",
      "Epoch 465/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0178 - accuracy: 0.9967 - val_loss: 0.7518 - val_accuracy: 0.8718\n",
      "Epoch 466/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.7386 - val_accuracy: 0.8754\n",
      "Epoch 467/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.7372 - val_accuracy: 0.8763\n",
      "Epoch 468/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 0.7509 - val_accuracy: 0.8768\n",
      "Epoch 469/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0184 - accuracy: 0.9964 - val_loss: 0.7420 - val_accuracy: 0.8761\n",
      "Epoch 470/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 0.9969 - val_loss: 0.7495 - val_accuracy: 0.8782\n",
      "Epoch 471/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9943 - val_loss: 0.7575 - val_accuracy: 0.8758\n",
      "Epoch 472/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9953 - val_loss: 0.7476 - val_accuracy: 0.8797\n",
      "Epoch 473/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 0.9972 - val_loss: 0.7697 - val_accuracy: 0.8752\n",
      "Epoch 474/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 0.9973 - val_loss: 0.7437 - val_accuracy: 0.8775\n",
      "Epoch 475/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0197 - accuracy: 0.9956 - val_loss: 0.7502 - val_accuracy: 0.8776\n",
      "Epoch 476/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.7480 - val_accuracy: 0.8767\n",
      "Epoch 477/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 0.9964 - val_loss: 0.7550 - val_accuracy: 0.8763\n",
      "Epoch 478/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0164 - accuracy: 0.9973 - val_loss: 0.7498 - val_accuracy: 0.8773\n",
      "Epoch 479/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9975 - val_loss: 0.7607 - val_accuracy: 0.8774\n",
      "Epoch 480/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0176 - accuracy: 0.9963 - val_loss: 0.7565 - val_accuracy: 0.8793\n",
      "Epoch 481/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0184 - accuracy: 0.9962 - val_loss: 0.7590 - val_accuracy: 0.8767\n",
      "Epoch 482/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9961 - val_loss: 0.7577 - val_accuracy: 0.8784\n",
      "Epoch 483/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.7559 - val_accuracy: 0.8783\n",
      "Epoch 484/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 0.9976 - val_loss: 0.7627 - val_accuracy: 0.8770\n",
      "Epoch 485/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0178 - accuracy: 0.9965 - val_loss: 0.7709 - val_accuracy: 0.8772\n",
      "Epoch 486/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 0.7648 - val_accuracy: 0.8766\n",
      "Epoch 487/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 0.9980 - val_loss: 0.7636 - val_accuracy: 0.8780\n",
      "Epoch 488/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9975 - val_loss: 0.7610 - val_accuracy: 0.8765\n",
      "Epoch 489/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9971 - val_loss: 0.7701 - val_accuracy: 0.8794\n",
      "Epoch 490/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9980 - val_loss: 0.7746 - val_accuracy: 0.8752\n",
      "Epoch 491/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 0.9983 - val_loss: 0.7726 - val_accuracy: 0.8756\n",
      "Epoch 492/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0137 - accuracy: 0.9984 - val_loss: 0.7700 - val_accuracy: 0.8776\n",
      "Epoch 493/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.7886 - val_accuracy: 0.8767\n",
      "Epoch 494/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0176 - accuracy: 0.9964 - val_loss: 0.7804 - val_accuracy: 0.8759\n",
      "Epoch 495/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 0.8308 - val_accuracy: 0.8688\n",
      "Epoch 496/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.8059 - val_accuracy: 0.8742\n",
      "Epoch 497/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0312 - accuracy: 0.9908 - val_loss: 0.7986 - val_accuracy: 0.8782\n",
      "Epoch 498/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 0.9954 - val_loss: 0.7814 - val_accuracy: 0.8769\n",
      "Epoch 499/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 0.9980 - val_loss: 0.7837 - val_accuracy: 0.8783\n",
      "Epoch 500/500\n",
      "47/47 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9971 - val_loss: 0.7841 - val_accuracy: 0.8779\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_scaled, train_target,\n",
    "                 validation_data = (val_scaled, val_target),\n",
    "                epochs=500, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6364f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], c='r')\n",
    "plt.plot(hist.history['val_loss'], c='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc863d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(a_layer=None, name=None):\n",
    "    model = keras.Sequential(name=name)\n",
    "    model.add(keras.layers.Dense(100, activation='relu', input_shape=(784,)))\n",
    "    if a_layer:\n",
    "        model.add(a_layer)\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "578c8b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_fun = model_fn(name='my_model')\n",
    "my_fun.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728c6f1",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f2fde89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(train_input, train_target), (test_input, test_target)\\\n",
    "= keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(train_input.shape, test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee456e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_scaled_pre = (train_input/255.).reshape(-1,28,28,1)\n",
    "test_scaled_pre = (test_input/255.).reshape(-1,28,28,1)\n",
    "\n",
    "print(train_scaled_pre.shape, test_scaled_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14bf3a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1) (12000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
    "    train_scaled_pre, train_target, test_size = 0.2, stratify=train_target\n",
    ")\n",
    "\n",
    "print(train_scaled.shape, val_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "309080a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 100)               57700     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,526\n",
      "Trainable params: 77,526\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "## ConvLayer1\n",
    "model.add(keras.layers.Conv2D(filters = 32, kernel_size=3,\n",
    "                              activation='relu', padding='same',\n",
    "                             strides = 1, input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "## convLayer2\n",
    "model.add(keras.layers.Conv2D(filters = 64, kernel_size=3,\n",
    "                             activation='relu', padding='same',\n",
    "                             strides = 2))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "## FCL\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f170fa04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0f59492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1de23bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True, to_file='cnn.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "645d07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ae1b4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "750/750 [==============================] - 18s 24ms/step - loss: 0.1792 - accuracy: 0.9342 - val_loss: 0.2449 - val_accuracy: 0.9127\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 18s 24ms/step - loss: 0.1695 - accuracy: 0.9373 - val_loss: 0.2602 - val_accuracy: 0.9071\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 18s 24ms/step - loss: 0.1600 - accuracy: 0.9401 - val_loss: 0.2512 - val_accuracy: 0.9147\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 19s 26ms/step - loss: 0.1505 - accuracy: 0.9440 - val_loss: 0.2674 - val_accuracy: 0.9099\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 20s 26ms/step - loss: 0.1421 - accuracy: 0.9481 - val_loss: 0.3062 - val_accuracy: 0.9022\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 19s 25ms/step - loss: 0.1342 - accuracy: 0.9501 - val_loss: 0.2937 - val_accuracy: 0.9015\n"
     ]
    }
   ],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint('./model/best_cnn_model.h5',\n",
    "                                             verbose=1)\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience = 5)\n",
    "\n",
    "hist = model.fit(train_scaled, train_target, epochs=100, batch_size=64,\n",
    "                validation_data = (val_scaled, val_target),\n",
    "                callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b882d2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], c='r')\n",
    "plt.plot(hist.history['val_loss'], c='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee7c36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "\n",
    "model = keras.models.load_model('./model/best_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7e5137c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.3241 - accuracy: 0.8964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3241187632083893, 0.896399974822998]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_scaled_pre, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "642b2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7f294879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test)\\\n",
    "= keras.datasets.mnist.load_data()\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97aae41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "float64 uint8\n"
     ]
    }
   ],
   "source": [
    "x_train = (x_train/255.).reshape(-1,28,28,1)\n",
    "x_test = (x_test/255.).reshape(-1,28,28,1)\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(x_train.dtype, y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "92b2057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu',\n",
    "                             input_shape=(28,28,1)))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=3, activation='relu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "318e7e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "390f2f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 1.2200 - accuracy: 0.5887\n",
      "Epoch 1: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 68s 224ms/step - loss: 1.2200 - accuracy: 0.5887 - val_loss: 0.3704 - val_accuracy: 0.8982\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4127 - accuracy: 0.8752\n",
      "Epoch 2: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.4127 - accuracy: 0.8752 - val_loss: 0.2595 - val_accuracy: 0.9235\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.8987\n",
      "Epoch 3: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 69s 229ms/step - loss: 0.3328 - accuracy: 0.8987 - val_loss: 0.2159 - val_accuracy: 0.9335\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.9099\n",
      "Epoch 4: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 224ms/step - loss: 0.2990 - accuracy: 0.9099 - val_loss: 0.1926 - val_accuracy: 0.9415\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2660 - accuracy: 0.9196\n",
      "Epoch 5: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 68s 227ms/step - loss: 0.2660 - accuracy: 0.9196 - val_loss: 0.1770 - val_accuracy: 0.9459\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.9250\n",
      "Epoch 6: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 224ms/step - loss: 0.2518 - accuracy: 0.9250 - val_loss: 0.1551 - val_accuracy: 0.9514\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9286\n",
      "Epoch 7: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.2336 - accuracy: 0.9286 - val_loss: 0.1459 - val_accuracy: 0.9544\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9329\n",
      "Epoch 8: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.2246 - accuracy: 0.9329 - val_loss: 0.1392 - val_accuracy: 0.9586\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.9347\n",
      "Epoch 9: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.2124 - accuracy: 0.9347 - val_loss: 0.1314 - val_accuracy: 0.9598\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2090 - accuracy: 0.9371\n",
      "Epoch 10: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.2090 - accuracy: 0.9371 - val_loss: 0.1271 - val_accuracy: 0.9618\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2013 - accuracy: 0.9395\n",
      "Epoch 11: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 224ms/step - loss: 0.2013 - accuracy: 0.9395 - val_loss: 0.1230 - val_accuracy: 0.9629\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.9403\n",
      "Epoch 12: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 223ms/step - loss: 0.1952 - accuracy: 0.9403 - val_loss: 0.1230 - val_accuracy: 0.9630\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9426\n",
      "Epoch 13: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.1877 - accuracy: 0.9426 - val_loss: 0.1135 - val_accuracy: 0.9654\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.9431\n",
      "Epoch 14: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.1867 - accuracy: 0.9431 - val_loss: 0.1155 - val_accuracy: 0.9659\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1801 - accuracy: 0.9454\n",
      "Epoch 15: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 68s 226ms/step - loss: 0.1801 - accuracy: 0.9454 - val_loss: 0.1116 - val_accuracy: 0.9668\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1799 - accuracy: 0.9453\n",
      "Epoch 16: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 68s 227ms/step - loss: 0.1799 - accuracy: 0.9453 - val_loss: 0.1108 - val_accuracy: 0.9681\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.9462\n",
      "Epoch 17: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 68s 226ms/step - loss: 0.1760 - accuracy: 0.9462 - val_loss: 0.1085 - val_accuracy: 0.9674\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.9459\n",
      "Epoch 18: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 224ms/step - loss: 0.1756 - accuracy: 0.9459 - val_loss: 0.1084 - val_accuracy: 0.9682\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9486\n",
      "Epoch 19: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.1691 - accuracy: 0.9486 - val_loss: 0.1059 - val_accuracy: 0.9678\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.9476\n",
      "Epoch 20: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.1703 - accuracy: 0.9476 - val_loss: 0.1120 - val_accuracy: 0.9655\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1660 - accuracy: 0.9485\n",
      "Epoch 21: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.1660 - accuracy: 0.9485 - val_loss: 0.1016 - val_accuracy: 0.9695\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1624 - accuracy: 0.9502\n",
      "Epoch 22: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.1624 - accuracy: 0.9502 - val_loss: 0.1054 - val_accuracy: 0.9693\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.9519\n",
      "Epoch 23: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.1578 - accuracy: 0.9519 - val_loss: 0.1010 - val_accuracy: 0.9685\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9519\n",
      "Epoch 24: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 68s 225ms/step - loss: 0.1557 - accuracy: 0.9519 - val_loss: 0.1013 - val_accuracy: 0.9689\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9525\n",
      "Epoch 25: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 68s 225ms/step - loss: 0.1539 - accuracy: 0.9525 - val_loss: 0.1105 - val_accuracy: 0.9656\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9516\n",
      "Epoch 26: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 68s 225ms/step - loss: 0.1565 - accuracy: 0.9516 - val_loss: 0.1016 - val_accuracy: 0.9696\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 0.9525\n",
      "Epoch 27: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 68s 227ms/step - loss: 0.1521 - accuracy: 0.9525 - val_loss: 0.0985 - val_accuracy: 0.9704\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.9542\n",
      "Epoch 28: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 68s 227ms/step - loss: 0.1495 - accuracy: 0.9542 - val_loss: 0.1010 - val_accuracy: 0.9706\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9539\n",
      "Epoch 29: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 68s 227ms/step - loss: 0.1497 - accuracy: 0.9539 - val_loss: 0.0969 - val_accuracy: 0.9719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.9539\n",
      "Epoch 30: saving model to ./model\\best_mnist_model.h5\n",
      "300/300 [==============================] - 67s 224ms/step - loss: 0.1484 - accuracy: 0.9539 - val_loss: 0.0982 - val_accuracy: 0.9698\n"
     ]
    }
   ],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint('./model/best_mnist_model.h5',\n",
    "                                            verbose=1)\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=5)\n",
    "\n",
    "hist = model.fit(x_train,y_train, epochs=30, batch_size=200,\n",
    "                validation_data = (x_test, y_test),\n",
    "                callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f6e36519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], c='r')\n",
    "plt.plot(hist.history['val_loss'], c='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ec893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
